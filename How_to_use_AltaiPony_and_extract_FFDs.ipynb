{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda622f5",
   "metadata": {},
   "source": [
    "# In this notebook are some steps on how to use AltaiPony to extract flares from photometry, estimate flare energies and calculate flare frequency distributions (FFD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1a6b5",
   "metadata": {},
   "source": [
    "# relevant imports and functions to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def apply_altai(ID, input_LC,smoothed_input_LC,\n",
    "               N1,N2,N3):\n",
    "    '''\n",
    "    This function is meant for detecting flares in photometry with AltaiPony.\n",
    "    \n",
    "    ============================================================\n",
    "    Inputs:\n",
    "    ID: ID number for target star, int or float\n",
    "    input_LC: time,flux,error arrays, pandas dataframe\n",
    "    smoothed_input_LC: detrended time,flux,error arrays, pandas dataframe\n",
    "    N1: How many times above sigma is required, float \n",
    "    N2: How many times above sigma and detrended_flux_err is required, float\n",
    "    N3: The number of consecutive points required to flag as a flare, float\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    Altai_flare_fits: table of measured flare parameters, pandas dataframe\n",
    "    '''\n",
    "    from altaipony.flarelc import FlareLightCurve\n",
    "    from altaipony.lcio import from_mast\n",
    "    # altaipony messes up matplotlib in jupyter notebook\n",
    "    # add these lines\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "    %matplotlib inline\n",
    "    \n",
    "    cad = np.nanmedian(np.diff(smoothed_input_LC))\n",
    "    \n",
    "    flc = FlareLightCurve(time=input_LC['time'], \\\n",
    "                             flux=input_LC['flux'],\\\n",
    "                             flux_err=input_LC['flux_err'])\n",
    "    flc.detrended_flux = smoothed_input_LC['flux']\n",
    "    flc.detrended_flux_err = smoothed_input_LC['flux_err']\n",
    "    flc.targetid=ID\n",
    "    \n",
    "    # turn off warnings since AltaiPony has deprecated pandas applications\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    flc = flc.find_flares(N1=N1,N2=N2,N3=N3)\n",
    "    flc = flc.flares.sort_values(by=\"ed_rec\", ascending=False)\n",
    "    \n",
    "    Altai_flare_fits = pd.DataFrame({'tstart': flc['tstart'],\n",
    "                               'tpeak': np.ones_like(flc['tstart'])*np.nan,\n",
    "                               'Fpeak': flc['ampl_rec'],\n",
    "                               'Npts': ((flc['tstop']-flc['tstart'])/cad).astype(int),\n",
    "                               'equiv_dur': flc['ed_rec'],\n",
    "                               'dur': flc['dur'],\n",
    "                               'FWHM': np.ones_like(flc['tstart'])*np.nan,\n",
    "                               'Validation': len(flc)*['Y']}).reset_index(drop=True)\n",
    "    \n",
    "    print(' ')\n",
    "    \n",
    "    return Altai_flare_fits\n",
    "\n",
    "\n",
    "def FFD(LC_summary, TOTEXP=1., Lum=30., fluxerr=0., dur=[], \n",
    "        logY=False, est_comp=False,is_altai=True):\n",
    "    '''\n",
    "    Given a set of stellar flares, with accompanying durations light curve properties,\n",
    "    compute the reverse cumulative Flare Frequency Distribution (FFD), and\n",
    "    approximate uncertainties in both energy and rate (X,Y) dimensions.\n",
    "    This diagram can be read as measuring the number of flares per day at a\n",
    "    given energy or larger.\n",
    "    Not a complicated task, just tedious.\n",
    "    Y-errors (rate) are computed using Poisson upper-limit approximation from\n",
    "    Gehrels (1986) \"Confidence limits for small numbers of events in astrophysical data\", https://doi.org/10.1086/164079\n",
    "    Eqn 7, assuming S=1.\n",
    "    X-errors (event energy) are computed following Signal-to-Noise approach commonly\n",
    "    used for Equivalent Widths in spectroscopy, from\n",
    "    Vollmann & Eversberg (2006) \"Astronomische Nachrichten, Vol.327, Issue 9, p.862\", https://dx.doi.org/10.1002/asna.200610645\n",
    "    Eqn 6.\n",
    "    Parameters\n",
    "    ----------\n",
    "    LC_summary : Pandas dataframe of measured flare parameters (tstart, tpeak, tstop, Fpeak, equiv_dur [days], dur [days])\n",
    "    TOTEXP : total duration of observations, in days\n",
    "    Lum : the log luminosity of the star\n",
    "    fluxerr : the average flux errors of your data (in relative flux units!)\n",
    "    dur : array of flare durations (in days).\n",
    "    logY : if True return Y-axis (and error) in log rate (Default: True)\n",
    "    est_comp : estimate incompleteness using histogram method, scale Y errors?\n",
    "        (Default: True)\n",
    "    is_altai: if True, accepts equiv_dur as in seconds already. if False, \n",
    "    converts from days to seconds\n",
    "    Returns\n",
    "    -------\n",
    "    ffd_x, ffd_y, ffd_xerr, ffd_yerr\n",
    "    X coordinate always assumed to be log_10(Energy)\n",
    "    Y coordinate is log_10(N/Day) by default, but optionally is N/Day\n",
    "    Upgrade Ideas\n",
    "    -------------\n",
    "    - More graceful behavior if only an array of flares and a total duration are\n",
    "        specified (i.e. just enough to make ffd_x, ffd_y)\n",
    "    - Better propogation of specific flux errors in the light curve, rather than\n",
    "        average error used\n",
    "    - Include detrending errors? (e.g. from a GP)\n",
    "    - Asymmetric Poisson errors?\n",
    "    - Better handling of incompleteness?\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    pd.options.mode.chained_assignment = None \n",
    "    from astropy.constants import iau2012 as const\n",
    "    # reverse sort flares in Equiv Dur\n",
    "    LC_summary=LC_summary.iloc[np.argsort(LC_summary['equiv_dur'].to_numpy())[::-1]]\n",
    "    ED=LC_summary['equiv_dur']\n",
    "    dur=LC_summary['dur'] #no duration...\n",
    "    #\n",
    "    # make ED & dur in seconds from days!\n",
    "    if is_altai==False:\n",
    "        ED = ED*24*60*60 # in seconds\n",
    "    else:\n",
    "        ED=ED\n",
    "    \n",
    "    # REVERSE sort the flares in energy\n",
    "    #ss = np.argsort(np.array(ED))[::-1]\n",
    "    #ffd_x = np.log10(ED[ss]) + Lum #ED must be in seconds for units of ffd_x to be in ergs\n",
    "    \n",
    "    ffd_x = np.log10(ED) + Lum #ED must be in seconds for units of ffd_x to be in ergs\n",
    "    \n",
    "    Num = np.arange(1, len(ffd_x)+1)\n",
    "    ffd_y = Num / TOTEXP\n",
    "\n",
    "    # approximate the Poisson Y errors using Gehrels (1986) eqn 7\n",
    "    Perror = np.sqrt(Num + 0.75) + 1.0\n",
    "    ffd_yerr = Perror / TOTEXP\n",
    "\n",
    "    # estimate completeness using the cumulative distribution of the histogram\n",
    "    if est_comp==True:\n",
    "        # make very loose guess at how many bins to choose\n",
    "        nbin = int(np.sqrt(len(ffd_x)))\n",
    "        if nbin < 10:\n",
    "            nbin=10 # but use at least 10 bins\n",
    "\n",
    "        # make histogram of the log(energies)\n",
    "        try:\n",
    "            hh, be = np.histogram(ffd_x, bins=nbin, range=[np.nanmin(ffd_x), np.nanmax(ffd_x)])\n",
    "        except ValueError:\n",
    "            hh, be = np.histogram(ffd_x, bins=nbin, range=[0, np.nanmax(ffd_x)])\n",
    "        hh = hh/np.nanmax(hh)\n",
    "        # make cumulative distribution of the histogram, scale to =1 at the hist peak\n",
    "        cc = np.cumsum(hh)/np.sum(hh[0:np.argmax(hh)])\n",
    "        be = (be[1:]+be[0:-1])/2\n",
    "        # make completeness = 1 for energies above the histogram peak\n",
    "        cc[np.argmax(hh):] = 1\n",
    "        # interpolate the cumulative histogram curve back to the original energies\n",
    "        ycomp = np.interp(ffd_x, be, cc)\n",
    "        # scale the y-errors by the completeness factor (i.e. inflate small energy errors)\n",
    "        ffd_yerr = ffd_yerr / ycomp\n",
    "\n",
    "    if logY:\n",
    "        # transform FFD Y and Y Error into log10\n",
    "        ffd_yerr = np.abs(ffd_yerr / np.log(10.) / ffd_y)\n",
    "        ffd_y = np.log10(ffd_y)\n",
    "        \n",
    "\n",
    "    # compute X uncertainties for FFD\n",
    "    if (len(dur)==len(ffd_x)):\n",
    "        # assume relative flux error = 1/SN\n",
    "        S2N = 1/fluxerr\n",
    "        \n",
    "        # based on Equivalent Width error\n",
    "        # Eqn 6, Vollmann & Eversberg (2006) Astronomische Nachrichten, Vol.327, Issue 9, p.862\n",
    "        ED_err = np.sqrt(2)*(dur* 24*60*60 - ED)/S2N\n",
    "        ffd_xerr = np.abs((ED_err) / np.log(10.) / ED) # convert to log\n",
    "    else:\n",
    "        # not particularly meaningful, but an interesting shape. NOT reccomended\n",
    "        # print('Warning: Durations not set. Making bad assumptions about the FFD X Error!')\n",
    "        ffd_xerr = (1/np.sqrt(ffd_x-np.nanmin(ffd_x))/(np.nanmax(ffd_x)-np.nanmin(ffd_x)))\n",
    "        \n",
    "        \n",
    "    #make sure values are finite ONLY (for polyfit reasons)\n",
    "    \n",
    "    LC_summary['ffd_x'] =    ffd_x\n",
    "    LC_summary['ffd_xerr'] = ffd_xerr\n",
    "    LC_summary['ffd_y'] =    ffd_y\n",
    "    LC_summary['ffd_yerr'] = ffd_yerr    \n",
    "    LC_summary=LC_summary.reset_index(drop=True)\n",
    "    print('FFD len check:',len(ffd_x),len(ffd_xerr),len(ffd_y),len(ffd_yerr))\n",
    "    #df = pd.DataFrame({'ffd_x':ffd_x,'ffd_xerr':ffd_xerr,'ffd_y':ffd_y,'ffd_yerr':ffd_yerr})\n",
    "#     with pd.option_context('mode.use_inf_as_null', True):\n",
    "#         df = df.dropna().reset_index(drop=True)\n",
    "    #ffd_x,ffd_xerr,ffd_y,ffd_yerr = df['ffd_x'],df['ffd_xerr'],df['ffd_y'],df['ffd_yerr']\n",
    "    #df=df.reset_index(drop=True)\n",
    "#     return np.array(ffd_x), np.array(ffd_y), np.array(ffd_xerr), np.array(ffd_yerr), df\n",
    "    return LC_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85040a42",
   "metadata": {},
   "source": [
    "# Notes on calculating Flare Energy:\n",
    "\n",
    "## See Eq 1 of https://iopscience.iop.org/article/10.3847/1538-4357/acbd36/pdf\n",
    "\n",
    "# $E_{\\mathrm{flare}} = \\int L_{\\mathrm{flare}}(t) dt = 2\\pi R_{\\mathrm{star}}^2 \\times \\sigma_{\\mathrm{SB}}T_{\\mathrm{eff}}^4 \\times \\frac{R(\\lambda)B(\\lambda, T_{\\mathrm{eff}} d\\lambda)}{R(\\lambda)B(\\lambda, T_{\\mathrm{flare}} d\\lambda)} \\times \\int \\frac{\\Delta F}{F}(t) dt$ \n",
    "## where \n",
    "## $\\frac{R(\\lambda)B(\\lambda, T_{\\mathrm{eff}} d\\lambda)}{R(\\lambda)B(\\lambda, T_{\\mathrm{flare}} d\\lambda)} = \\mathrm{\"flux~ratio\"}$ and $\\int \\frac{\\Delta F}{F}(t) dt =~\\mathrm{\"equivalent~duration\"}$\n",
    "\n",
    "# so to simplify\n",
    "\n",
    "$E_{\\mathrm{flare}} = \\mathrm{flux~ratio} \\times 2\\pi R_{\\mathrm{star}}^2 \\times \\sigma_{\\mathrm{SB}}T_{\\mathrm{eff}}^4 \\times \\mathrm{equivalent~duration}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flare_factor(teff, radius, wav, resp,  tflare=float(1e4)):\n",
    "    \"\"\"Calculate the flare energy factor in ergs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    teff : float\n",
    "        Stellar effective temperature in Kelvin.\n",
    "    radius : float\n",
    "        Stellar radius in solar radii.\n",
    "    wav : array\n",
    "        Array of wavelengths in nanometers.\n",
    "    resp : array\n",
    "        Array of bandpass responses.\n",
    "     tflare : float\n",
    "        Flare temperature in Kelvin. Default 10,000 K.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    factor : float\n",
    "        Flare energy factor in ergs/s.\n",
    "    \"\"\"\n",
    "    from astropy.modeling import models\n",
    "    from astropy import units as u\n",
    "    from astropy.constants import sigma_sb\n",
    "\n",
    "    # blackbody\n",
    "    bb = models.BlackBody(temperature=teff * u.K)\n",
    "\n",
    "    # blackbody flux in TESS band\n",
    "    bbwavs = bb(wav * u.nm)  * resp\n",
    "\n",
    "    fluxstar = np.trapz(bbwavs.value, wav)\n",
    "\n",
    "    # blackbody\n",
    "    bb = models.BlackBody(temperature=tflare * u.K)\n",
    "\n",
    "    # blackbody flux in TESS band\n",
    "    bbwavf = bb(wav * u.nm)  * resp\n",
    "\n",
    "    fluxflare = np.trapz(bbwavf.value, wav)\n",
    "\n",
    "    ratio = fluxstar / fluxflare\n",
    "\n",
    "    #print(\"TESS\", ratio)\n",
    "\n",
    "    factor = ratio * np.pi * (radius * u.R_sun) ** 2 * sigma_sb * (tflare * u.K)**4\n",
    "    factor = factor.to(\"erg/s\")\n",
    "    print(factor)\n",
    "    return factor\n",
    "\n",
    "kepler_bandpass = np.transpose(np.loadtxt('https://nexsci.caltech.edu/workshop/2012/keplergo/kepler_response_hires1.txt', skiprows=6, comments='#',encoding='utf-16'))\n",
    "kepler_bandpass = pd.DataFrame({'Wavelength (nm)':kepler_bandpass[0], 'lambda Transmission':kepler_bandpass[1]})\n",
    "tess_bandpass = pd.read_csv('https://heasarc.gsfc.nasa.gov/docs/tess/data/tess-response-function-v2.0.csv',skiprows=5)\n",
    "tess_bandpass=tess_bandpass.rename(columns={'# Wavelength (nm)':'Wavelength (nm)',' lambda Transmission':'lambda Transmission' })\n",
    "\n",
    "\n",
    "tess_bandpass['Wavelength (Angstrom)'] = tess_bandpass['Wavelength (nm)']*10\n",
    "kepler_bandpass['Wavelength (Angstrom)'] = kepler_bandpass['Wavelength (nm)']*10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc4973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c524e0e7",
   "metadata": {},
   "source": [
    "# example: YZ CMi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446e11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e4bb7d5",
   "metadata": {},
   "source": [
    "# grab 2min TESS light curves (this might take a few minutes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "from lightkurve import search_targetpixelfile\n",
    "\n",
    "starname='TIC 266744225'\n",
    "ID=int(starname[4:])\n",
    "\n",
    "tpf_search = search_targetpixelfile(starname) #this will get tpfs for custom extraction, above method gets light curves from SPOC\n",
    "tpf_search_SPOC = tpf_search[tpf_search.author=='SPOC']\n",
    "tpf_search_SPOC = tpf_search_SPOC[tpf_search_SPOC.exptime.value>20]\n",
    "tpf_search_SPOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84577a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "S7tpf = tpf_search_SPOC[0].download(quality_bitmask='hardest',download_dir=os.getcwd()+'/')\n",
    "S34tpf= tpf_search_SPOC[1].download(quality_bitmask='hardest',download_dir=os.getcwd()+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a13a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_region_for_nearby_stars(ID,radial_cone_in_arcsecs):\n",
    "    #stuff for getting FFI data from MAST\n",
    "    from astroquery.mast import Catalogs\n",
    "    import numpy as np\n",
    "    import time as clock\n",
    "    import requests\n",
    "\n",
    "    starName=\"TIC \"+str(ID)\n",
    "    radial_cone = radial_cone_in_arcsecs/ 3600.0 # angular radius in degrees\n",
    "    try:\n",
    "        catalogData = Catalogs.query_object(starName, radius = radial_cone, catalog = \"TIC\")\n",
    "    except requests.exceptions.ConnectionError as E:\n",
    "        clock.sleep(5) #pause 5 seconds then try again\n",
    "        catalogData = Catalogs.query_object(starName, radius = radSearch, catalog = \"TIC\")\n",
    "    #    \n",
    "    return catalogData\n",
    "\n",
    "def convert_TessMag_to_Flux(Tmag):\n",
    "    f = 10**(-(Tmag/2.5))\n",
    "    return f\n",
    "\n",
    "def calc_flux_contamination(ID,radial_cone_in_arcseconds=63):\n",
    "\n",
    "    catalogData = query_region_for_nearby_stars(ID,radial_cone_in_arcseconds)\n",
    "\n",
    "    Tmag_target_star = catalogData[0]['Tmag']\n",
    "    Flux_target_star = convert_TessMag_to_Flux(Tmag_target_star)\n",
    "    Flux_all = []\n",
    "    for t in range(len(catalogData)):\n",
    "        Flux_all = np.append(Flux_all, convert_TessMag_to_Flux(catalogData[t]['Tmag']))\n",
    "    Flux_total = np.sum(Flux_all)\n",
    "\n",
    "    flux_contamination_ratio = Flux_target_star / Flux_total #this is light FROM the target star\n",
    "    flux_contamination_ratio = 1 - Flux_target_star / Flux_total #this is light NOT FROM the target star (will produce ratio=0 for 1 - 10^(-Tmag,target/2.5) / 10^(-Tmag,target/2.5)\n",
    "\n",
    "    return flux_contamination_ratio\n",
    "\n",
    "def Extract_LC(lk_object,threshold,bkg_threshold,TPForFFI):\n",
    "    import pandas as pd\n",
    "    if TPForFFI=='TPF':\n",
    "        target_mask = lk_object.hdu[2].data & 2 > 0 #SPOC optimal aperture\n",
    "    else:    \n",
    "        target_mask = lk_object.create_threshold_mask(threshold=threshold, reference_pixel='center')\n",
    "    \n",
    "    n_target_pixels = target_mask.sum()\n",
    "    target_lc = lk_object.to_lightcurve(aperture_mask=target_mask)\n",
    "    background_mask = ~lk_object.create_threshold_mask(threshold=bkg_threshold, reference_pixel=None)\n",
    "    n_background_pixels = background_mask.sum()\n",
    "\n",
    "    \n",
    "    background_lc_per_pixel = lk_object.to_lightcurve(aperture_mask=background_mask) / n_background_pixels\n",
    "    background_estimate_lc = background_lc_per_pixel * n_target_pixels\n",
    "    raw_bkg=background_estimate_lc.remove_nans()\n",
    "    norm_bkg=background_estimate_lc.normalize()\n",
    "    cnew=target_lc - background_estimate_lc.flux\n",
    "    cnew=cnew.remove_nans()#.remove_outliers() #<---- this truncates transits!!!\n",
    "    \n",
    "    raw_lc=target_lc#cnew\n",
    "    corrected_lc = cnew.normalize()\n",
    "    \n",
    "    quality_mask = np.where(corrected_lc.quality==0)[0]\n",
    "    \n",
    "    corrected_lc = corrected_lc[quality_mask]\n",
    "    norm_bkg = norm_bkg[quality_mask]\n",
    "    raw_lc = raw_lc[quality_mask]\n",
    "    raw_bkg = raw_bkg[quality_mask]\n",
    "    \n",
    "    \n",
    "    #b/c new lightkurve is weird and now requires .value for arrays, use pandas\n",
    "    \n",
    "    \n",
    "    #deblend all light curves within 2 TESS pixels\n",
    "    f_contam_ratio = calc_flux_contamination(ID,radial_cone_in_arcseconds=21*2)\n",
    "    \n",
    "    deblended_corrected_lc_flux = corrected_lc.flux.value - f_contam_ratio\n",
    "    deblended_corrected_lc_flux = deblended_corrected_lc_flux / np.nanmedian(deblended_corrected_lc_flux)\n",
    "    \n",
    "    deblended_raw_lc_flux = raw_lc.flux.value - f_contam_ratio\n",
    "    deblended_raw_lc_flux = deblended_raw_lc_flux #/ np.nanmedian(deblended_raw_lc_flux)\n",
    "    \n",
    "    corrected_lc = pd.DataFrame({'time':corrected_lc.time.value,'flux':deblended_corrected_lc_flux,\\\n",
    "                                'flux_err':corrected_lc.flux_err.value})\n",
    "    norm_bkg = pd.DataFrame({'time':norm_bkg.time.value,'flux':norm_bkg.flux.value,\\\n",
    "                                'flux_err':norm_bkg.flux_err.value})\n",
    "    raw_lc = pd.DataFrame({'time':raw_lc.time.value,'flux':deblended_raw_lc_flux,\\\n",
    "                                'flux_err':raw_lc.flux_err.value})\n",
    "    raw_bkg = pd.DataFrame({'time':raw_bkg.time.value,'flux':raw_bkg.flux.value,\\\n",
    "                                'flux_err':raw_bkg.flux_err.value})\n",
    "    \n",
    "    #for PLD detrending later\n",
    "    \n",
    "#     print(corrected_lc.time.value)\n",
    "#     print(deblended_corrected_lc_flux)\n",
    "#     print(corrected_lc.flux_err.value)\n",
    "#     print(deblended_raw_lc_flux)\n",
    "#     print(raw_bkg.flux.value)\n",
    "    \n",
    "    master_lc = pd.DataFrame({'Time':np.array(corrected_lc['time']),\\\n",
    "                              'SAP Flux':deblended_corrected_lc_flux,\\\n",
    "                              'SAP Error':np.array(corrected_lc['flux_err']),\\\n",
    "                              'RAW SAP Flux':deblended_raw_lc_flux,\\\n",
    "                              'Background Flux':np.array(raw_bkg['flux'])})\n",
    "    \n",
    "    \n",
    "    return corrected_lc, norm_bkg, raw_lc, raw_bkg, master_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11ea6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "S7_TPF_LC, S7_TPF_BKG, S7_TPF_RAWLC, S7_TPF_RAWBKG, S7_TPF_master  = Extract_LC(S7tpf, threshold=3,bkg_threshold=1/1000,TPForFFI='TPF')\n",
    "S34_TPF_LC,S34_TPF_BKG,S34_TPF_RAWLC,S34_TPF_RAWBKG,S34_TPF_master = Extract_LC(S34tpf,threshold=3,bkg_threshold=1/1000,TPForFFI='TPF')\n",
    "\n",
    "# Let's see what the photometry looks like:\n",
    "\n",
    "fs=16\n",
    "fig=plt.figure(figsize=(14,7))\n",
    "ax1=fig.add_subplot(221)\n",
    "ax2=fig.add_subplot(222)\n",
    "\n",
    "\n",
    "def plot_LC(LC,ax,label):\n",
    "    try:\n",
    "        ax.plot(LC.time,LC.flux,'k.',markersize=5)\n",
    "        ax.set_ylim(np.nanmin(LC.flux)-3*np.nanstd(LC.flux),np.nanmax(LC.flux)+3*np.nanstd(LC.flux))\n",
    "    except AttributeError: #for PLD detrended LCs, later\n",
    "        ax.plot(LC['Time'],LC['PLD Flux'],'k.',markersize=5)\n",
    "        ax.set_ylim(np.nanmin(LC['PLD Flux'])-3*np.nanstd(LC['PLD Flux']),np.nanmax(LC['PLD Flux'])+3*np.nanstd(LC['PLD Flux']))        \n",
    "    ax.tick_params(axis='both', which='major', labelsize=fs)\n",
    "    ax.set_xlabel('Time (BTJD)',fontsize=fs)\n",
    "    ax.set_rasterized(True)\n",
    "    ax.set_title(label,fontsize=fs)\n",
    "    \n",
    "ax1.set_ylabel('Normalized Relative Flux',fontsize=fs)    \n",
    "\n",
    "plot_LC(S7_TPF_LC,ax1,label='Sector 7')\n",
    "plot_LC(S34_TPF_LC,ax2,label='Sector 34')\n",
    "\n",
    "ymin,ymax = np.min([ax1.get_ylim(),ax2.get_ylim()]),np.max([ax1.get_ylim(),ax2.get_ylim()])\n",
    "ax1.set_ylim(ymin,ymax)\n",
    "ax2.set_ylim(ymin,ymax)\n",
    "\n",
    "fig.suptitle(starname+' Light Curves',x=0.5,y=0.975,fontsize=fs)\n",
    "fig.tight_layout(pad=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef38762e",
   "metadata": {},
   "source": [
    "# Smooth LC for easier detection (use your favorite algorithm!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a146c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I'll use lightkurve's savitsky-golay filter (which is pretty commonly used)\n",
    "\n",
    "def detrend(input_LC,window_size,polyorder):\n",
    "\n",
    "    import lightkurve as lk\n",
    "\n",
    "\n",
    "    cadence = np.nanmedian(np.diff(input_LC.time))\n",
    "    def round_up_to_odd(f): #must be an odd number!\n",
    "        return int(np.ceil(f) // 2 * 2 + 1)\n",
    "    Npts = round_up_to_odd(int((window_size)/cadence)) \n",
    "    print('Smoothing Window in days:',window_size,'; in data points:',Npts)\n",
    "    \n",
    "    detrended_lc,trend_lc = lk.LightCurve(time=input_LC.time,\n",
    "                                          flux=input_LC.flux,\n",
    "                                          flux_err=input_LC.flux_err).flatten(window_length=Npts,\n",
    "                                                                              polyorder=polyorder, \n",
    "                                                                              return_trend=True)\n",
    "    #instead of retuning lk.LightCurve, return pandas dataframe instead\n",
    "    import pandas as pd\n",
    "    detrended_lc = pd.DataFrame({'time':detrended_lc.time.value,\n",
    "                                'flux':detrended_lc.flux.value,\n",
    "                                'flux_err':detrended_lc.flux_err.value})\n",
    "    trend_lc = pd.DataFrame({'time':trend_lc.time.value,\n",
    "                             'flux':trend_lc.flux.value,\n",
    "                             'flux_err':trend_lc.flux_err.value})\n",
    "    return detrended_lc,trend_lc\n",
    "\n",
    "S7_detrended_lc, S7_trend_lc = detrend(input_LC = S7_TPF_LC,\n",
    "                            window_size=12/24,\n",
    "                            polyorder=3)\n",
    "\n",
    "fs=12\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_subplot(221)\n",
    "ax2=fig.add_subplot(222)\n",
    "\n",
    "ax.scatter(S7_TPF_LC.time,S7_TPF_LC.flux,color='black',s=1)\n",
    "ax.plot(S7_trend_lc.time,S7_trend_lc.flux,color='red',lw=2)\n",
    "ax2.scatter(S7_detrended_lc.time,S7_detrended_lc.flux,color='black',s=1)\n",
    "fig.suptitle('Sector 7',x=0.5,y=0.975)\n",
    "ax.set_ylabel('Normalized Relative Flux',fontsize=fs)    \n",
    "ax.set_xlabel('Time (BTJD)',fontsize=fs)\n",
    "ax2.set_xlabel('Time (BTJD)',fontsize=fs)\n",
    "fig.tight_layout(pad=1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "S34_detrended_lc, S34_trend_lc = detrend(input_LC = S34_TPF_LC,\n",
    "                            window_size=12/24,\n",
    "                            polyorder=3)\n",
    "\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "ax=fig.add_subplot(221)\n",
    "ax2=fig.add_subplot(222)\n",
    "ax.scatter(S34_TPF_LC.time,S34_TPF_LC.flux,color='black',s=1)\n",
    "ax.plot(S34_trend_lc.time,S34_trend_lc.flux,color='red',lw=2)\n",
    "ax2.scatter(S34_detrended_lc.time,S34_detrended_lc.flux,color='black',s=1)\n",
    "fig.suptitle('Sector 34',x=0.5,y=0.975)\n",
    "ax.set_ylabel('Normalized Relative Flux',fontsize=fs)    \n",
    "ax.set_xlabel('Time (BTJD)',fontsize=fs)\n",
    "ax2.set_xlabel('Time (BTJD)',fontsize=fs)\n",
    "fig.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead69209",
   "metadata": {},
   "source": [
    "# Next, use AltaiPony to detect flares. I recommend defining N1 = 2, N2=1 and defining N3 based on cadence of the light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1=2\n",
    "N2=1\n",
    "\n",
    "if np.nanmedian(np.diff(S7_detrended_lc['time']))*24*60*60 < 60:\n",
    "    N3=5    \n",
    "if (np.nanmedian(np.diff(S7_detrended_lc['time']))*24*60*60 > 60)  & (np.nanmedian(np.diff(S7_detrended_lc['time']))*24*60 <= 30):\n",
    "    N3=3\n",
    "print(N1,N2,N3)    \n",
    "\n",
    "\n",
    "flc_7 = apply_altai(ID=ID, \n",
    "                    input_LC=S7_TPF_LC,\n",
    "                    smoothed_input_LC=S7_detrended_lc,\n",
    "                    N1=N1,N2=N2,N3=N3)\n",
    "\n",
    "\n",
    "flc_34 = apply_altai(ID=ID, \n",
    "                     input_LC=S34_TPF_LC,\n",
    "                     smoothed_input_LC=S34_detrended_lc,\n",
    "                     N1=N1,N2=N2,N3=N3)\n",
    "\n",
    "# how to combine the light curves \n",
    "input_LC = S7_TPF_LC.append(S34_TPF_LC)\n",
    "smoothed_input_LC = S7_detrended_lc.append(S34_detrended_lc)\n",
    "\n",
    "flc_7_and_34 = apply_altai(ID=ID, input_LC=input_LC,\n",
    "                           smoothed_input_LC=smoothed_input_LC,\n",
    "                           N1=N1,N2=N2,N3=N3)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d557b",
   "metadata": {},
   "source": [
    "# estimate flare energy based on Kepler, TESS passbands and a blackbody of a given temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e7db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Baroach et al. 2020 https://www.aanda.org/articles/aa/pdf/2020/09/aa38213-20.pdf\n",
    "R_star = 0.369\n",
    "R_star_unc= np.mean([0.027,0.055])\n",
    "M_star = R_star #ASSUMPTION, NOT LISTED\n",
    "M_star_unc = R_star_unc #ASSUMPTION, NOT LISTED\n",
    "Teff = 3100\n",
    "Teff_unc = np.mean([50])\n",
    "distance = 5.9874 #pc\n",
    "logg =  5\n",
    "\n",
    "\n",
    "# ex usage: \n",
    "print('TESS flare energy for 10,000 K flare')\n",
    "tess_flare_factor = flare_factor(teff=Teff, radius=R_star, wav = tess_bandpass[\"Wavelength (nm)\"].values, resp=tess_bandpass[\"lambda Transmission\"].values)    \n",
    "print(' ')\n",
    "print('Kepler flare energy for 10,000 K flare')\n",
    "kepler_flare_factor = flare_factor(teff=Teff, radius=R_star, wav = kepler_bandpass[\"Wavelength (nm)\"].values, resp=kepler_bandpass[\"lambda Transmission\"].values)    \n",
    "print(' ')\n",
    "# nflares[\"ed_rec\"] = nflares.ed_rec * factor.value\n",
    "# nflares[\"ed_rec_err\"] = nflares.ed_rec_err * factor.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350885b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate total exposure time (cadence times LC duration)\n",
    "tess_exp_7 = np.nanmedian(np.diff(S7_detrended_lc.time))  * len(S7_detrended_lc.time)\n",
    "tess_exp_34 = np.nanmedian(np.diff(S34_detrended_lc.time))  * len(S34_detrended_lc.time)\n",
    "tess_exp_7_and_34 = np.nanmedian(np.diff(smoothed_input_LC.time))  * len(smoothed_input_LC.time)\n",
    "\n",
    "# provide flux uncertainties\n",
    "flux_err_7 = np.nanmedian(S7_detrended_lc.flux_err)/np.nanmedian(S7_detrended_lc.flux)\n",
    "flux_err_34 = np.nanmedian(S34_detrended_lc.flux_err)/np.nanmedian(S34_detrended_lc.flux)\n",
    "flux_err_7_and_34 = np.nanmedian(smoothed_input_LC.flux_err)/np.nanmedian(smoothed_input_LC.flux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f08e009",
   "metadata": {},
   "source": [
    "# plot FFD distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not sure about using this...\n",
    "# def plot_flare_rate_lines(ax1,ax2,xmin,rate,rate_str):\n",
    "#     if xmin==None:\n",
    "#         xmin = np.min([ax1.get_xlim(),ax2.get_xlim()])\n",
    "#     ax1.axhline(y=rate,linestyle='--',zorder=-10)\n",
    "#     ax1.text(x=xmin+xmin*1/1000,y=rate+rate*1/10,s=rate_str,transform=ax1.transData)\n",
    "#     ax2.axhline(y=rate,linestyle='--',zorder=-10)\n",
    "#     ax2.text(x=xmin+xmin*1/1000,y=rate+rate*1/10,s=rate_str,transform=ax2.transData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8a9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af31c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logY=False\n",
    "\n",
    "# if we set flare luminosity to zero, the \"flare energies\"\n",
    "# are equal to the equivalent durations of the flares\n",
    "Lflare = 0\n",
    "\n",
    "flc_7_ffd = FFD(flc_7, TOTEXP=tess_exp_7, \n",
    "                Lum=Lflare, fluxerr=flux_err_7, dur=[], \n",
    "                logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "flc_34_ffd = FFD(flc_34, TOTEXP=tess_exp_34, \n",
    "                   Lum=Lflare, fluxerr=flux_err_34, dur=[], \n",
    "        logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "flc_7_and_34_ffd = FFD(flc_7_and_34, TOTEXP=tess_exp_7_and_34, \n",
    "                         Lum=Lflare, fluxerr=flux_err_7_and_34, dur=[], \n",
    "        logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(10,8))\n",
    "ax1=fig.add_subplot(221)\n",
    "ax2=fig.add_subplot(222)\n",
    "\n",
    "\n",
    "ax1.scatter(flc_7_ffd['ffd_x'],flc_7_ffd['ffd_y'],label='YZ CMi Sector 7\\n '+str(len(flc_7_ffd))+' flares',color='black')\n",
    "ax1.scatter(flc_34_ffd['ffd_x'],flc_34_ffd['ffd_y'],label='YZ CMi Sector 34\\n '+str(len(flc_34_ffd))+' flares',color='red')\n",
    "\n",
    "ax2.scatter(flc_7_and_34_ffd['ffd_x'],flc_7_and_34_ffd['ffd_y'],label='YZ CMi Sector 7 & 34\\n '+str(len(flc_7_and_34_ffd))+' flares',color='grey')\n",
    "\n",
    "\n",
    "# plt.xlim(35.5,38)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('log Equivalent Duration [seconds]',fontsize=12)\n",
    "ax1.set_ylabel('log Flare Rate (day$^{-1}$)',fontsize=12)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('log Equivalent Duration [seconds]',fontsize=12)\n",
    "ax2.set_ylabel('log Flare Rate (day$^{-1}$)',fontsize=12)\n",
    "\n",
    "\n",
    "ymin,ymax= 1e-2,15\n",
    "ax1.set_ylim(ymin,ymax)\n",
    "ax2.set_ylim(ymin,ymax)\n",
    "\n",
    "ymin,ymax = np.min([ax1.get_ylim(),ax2.get_ylim()]),np.max([ax1.get_ylim(),ax2.get_ylim()])\n",
    "ax1.set_ylim(ymin,ymax)\n",
    "ax2.set_ylim(ymin,ymax)\n",
    "\n",
    "xmin,xmax = -2,4\n",
    "ax1.set_xlim(xmin,xmax)\n",
    "ax2.set_xlim(xmin,xmax)\n",
    "# I'm not sure about using this...\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=1/24,rate_str='per hour',xmin=xmin)\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=1,rate_str='per day',xmin=xmin)\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=7,rate_str='per week',xmin=xmin)\n",
    "\n",
    "ax1.legend(loc='upper right',fontsize=8,ncol=1)#,bbox_to_anchor=(1,1))\n",
    "ax2.legend(loc='upper right',fontsize=8,ncol=2)#,bbox_to_anchor=(1,1))\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "plt.show()\n",
    "\n",
    "print('\\n==========================================\\n')\n",
    "\n",
    "# now let's use an actual flare energy\n",
    "Lflare = np.log10(tess_flare_factor.value)\n",
    "\n",
    "flc_7_ffd = FFD(flc_7, TOTEXP=tess_exp_7, \n",
    "                Lum=Lflare, fluxerr=flux_err_7, dur=[], \n",
    "                logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "flc_34_ffd = FFD(flc_34, TOTEXP=tess_exp_34, \n",
    "                   Lum=Lflare, fluxerr=flux_err_34, dur=[], \n",
    "        logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "flc_7_and_34_ffd = FFD(flc_7_and_34, TOTEXP=tess_exp_7_and_34, \n",
    "                         Lum=Lflare, fluxerr=flux_err_7_and_34, dur=[], \n",
    "        logY=logY, est_comp=False,is_altai=True)\n",
    "\n",
    "fig=plt.figure(figsize=(10,8))\n",
    "ax1=fig.add_subplot(221)\n",
    "ax2=fig.add_subplot(222)\n",
    "\n",
    "\n",
    "ax1.scatter(flc_7_ffd['ffd_x'],flc_7_ffd['ffd_y'],label='YZ CMi Sector 7\\n '+str(len(flc_7_ffd))+' flares',color='black')\n",
    "ax1.scatter(flc_34_ffd['ffd_x'],flc_34_ffd['ffd_y'],label='YZ CMi Sector 34\\n '+str(len(flc_34_ffd))+' flares',color='red')\n",
    "\n",
    "ax2.scatter(flc_7_and_34_ffd['ffd_x'],flc_7_and_34_ffd['ffd_y'],label='YZ CMi Sector 7 & 34\\n '+str(len(flc_7_and_34_ffd))+' flares',color='grey')\n",
    "\n",
    "\n",
    "# plt.xlim(35.5,38)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('log Flare Energy [ergs]',fontsize=12)\n",
    "ax1.set_ylabel('log Flare Rate (day$^{-1}$)',fontsize=12)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('log Flare Energy [ergs]',fontsize=12)\n",
    "ax2.set_ylabel('log Flare Rate (day$^{-1}$)',fontsize=12)\n",
    "\n",
    "\n",
    "ymin,ymax= 1e-2,15\n",
    "ax1.set_ylim(ymin,ymax)\n",
    "ax2.set_ylim(ymin,ymax)\n",
    "\n",
    "ymin,ymax = np.min([ax1.get_ylim(),ax2.get_ylim()]),np.max([ax1.get_ylim(),ax2.get_ylim()])\n",
    "\n",
    "ax1.set_ylim(ymin,ymax)\n",
    "ax2.set_ylim(ymin,ymax)\n",
    "\n",
    "xmin,xmax = 30.-0.5,35\n",
    "ax1.set_xlim(xmin,xmax)\n",
    "ax2.set_xlim(xmin,xmax)\n",
    "\n",
    "# I'm not sure about using this...\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=1/24,rate_str='per hour',xmin=xmin)\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=1,rate_str='per day',xmin=xmin)\n",
    "# plot_flare_rate_lines(ax1,ax2,rate=7,rate_str='per week',xmin=xmin)\n",
    "\n",
    "\n",
    "\n",
    "ax1.legend(loc='upper right',fontsize=8,ncol=1)#,bbox_to_anchor=(1,1))\n",
    "ax2.legend(loc='upper right',fontsize=8,ncol=2)#,bbox_to_anchor=(1,1))\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "loc = plticker.MultipleLocator(base=1) # this locator puts ticks at regular intervals\n",
    "ax1.xaxis.set_major_locator(loc)\n",
    "ax2.xaxis.set_major_locator(loc)\n",
    "\n",
    "fig.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all done! :D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83218c41",
   "metadata": {},
   "source": [
    "# what' going on with this large flare 10^35 ergs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06268729",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_alt=flc_7_and_34_ffd.iloc[np.argmax(flc_7_and_34_ffd['equiv_dur'])]\n",
    "big_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec976796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(smoothed_input_LC.time,smoothed_input_LC.flux,s=1,color='black')\n",
    "\n",
    "\n",
    "plt.axvspan(xmin=big_alt['tstart'],xmax=big_alt['tstart']+big_alt['dur'],color='grey',alpha=0.5,zorder=-10)\n",
    "plt.xlim(big_alt['tstart']-big_alt['dur'],big_alt['tstart']+2*(big_alt['dur']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_alt[['dur','equiv_dur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ab92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
